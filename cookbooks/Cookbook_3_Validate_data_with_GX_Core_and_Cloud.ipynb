{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cookbook 3: Validate data with GX Core and GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "**Note:** ***The GX Cloud UI screenshots contained in this cookbook are current as of*** `2025-01-06`. ***As GX Cloud continues to evolve, it is possible that you will see a difference between the latest UI and the screenshots displayed here.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This cookbook showcases a data validation workflow characteristic of vetting existing data in an organization's data stores. It could be representative of two groups within an organization enforcing a publisher-subscriber data contract, or representative of users ensuring that data meets the quality requirements for its intended use, such as analytics or modeling.\n",
    "\n",
    "[Cookbook 1](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb) and [Cookbook 2](Cookbook_2_Validate_data_during_ingestion_take_action_on_failures.ipynb) explored GX Core workflows that were run within a data pipeline, orchestrated by Airflow. This cookbook introduces [GX Cloud](https://greatexpectations.io/gx-cloud) as an additional tool to store and visualize data validation results and features a hybrid workflow using GX Core, GX Cloud, and Airflow.\n",
    "\n",
    "This cookbook builds on [Cookbook 1: Validate data during ingestion (happy path)](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb) and [Cookbook 2: Validate data during ingestion (take action on failures)](Cookbook_2_Validate_data_during_ingestion_take_action_on_failures.ipynb) and focuses on how data validation failures can be programmatically handled in the pipeline based on GX Validation Results and how failures can be shared using GX Cloud. This cookbook assumes basic familiarity with GX Core workflows; for a step-by-step explanation of the GX data validation workflow, refer to [Cookbook 1](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb) and [Cookbook 2](Cookbook_2_Validate_data_during_ingestion_take_action_on_failures.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "The GX Core content of this cookbook uses the `great_expectations` library.\n",
    "\n",
    "The `tutorial_code` module contains helper functions used within this notebook and the associated Airflow pipeline.\n",
    "\n",
    "The `airflow_dags` submodule is included so that you can inspect the code used in the related Airflow DAG directly from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "import great_expectations as gx\n",
    "import great_expectations.expectations as gxe\n",
    "import IPython\n",
    "import pandas as pd\n",
    "\n",
    "import tutorial_code as tutorial\n",
    "import airflow_dags.cookbook3_validate_postgres_table_data as dag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## The GX data quality platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The Great Expectations data quality platform is comprised by:\n",
    "* [GX Cloud](https://greatexpectations.io/gx-cloud), a fully managed SaaS solution, with web portal, and\n",
    "* [GX Core](https://github.com/great-expectations/great_expectations), the open source Python framework.\n",
    "\n",
    "GX Cloud and GX Core can be used separately for a cloud-only or programmatic-only approach ([Cookbook 1](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb) and [Cookbook 2](Cookbook_2_Validate_data_during_ingestion_take_action_on_failures.ipynb) are an example of a Core-only workflow). However, using GX Core and GX Cloud *together* provides a solution in which GX Cloud serves as a single source of truth for data quality definition and application, and GX Core enables flexible integration of data validation into existing data stacks. Together, GX Cloud and GX Core enable you to achieve data quality definition, monitoring, and management using UI-based workflows, programmatic workflows, or hybrid workflows.\n",
    "\n",
    "The diagram below depicts different ways you might opt to use the platform (but is not exhaustive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/diagrams/gx_cloud_core_architecture.png\",\n",
    "    alt=\"Example modes of working together with GX Cloud and GX Core\",\n",
    "    width=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Cookbook workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "In this cookbook, you will use GX Core, GX Cloud, and Airflow to define data quality for sample data, run data validation, and explore the results of data validation. The key steps are:\n",
    "1. Define your Data Asset, Expectations, and Checkpoint programmatically with GX Core\n",
    "2. Store the GX workflow configuration in your GX Cloud organization\n",
    "3. Trigger data validation from an Airflow pipeline\n",
    "4. Explore data validation results in GX Cloud\n",
    "\n",
    "The diagram below depicts, in more detail, the underlying interactions of GX Core, GX Cloud, Airflow, and the sample data Postgres database. As you work through this cookbook, you'll implement each of these interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/diagrams/cookbook3_workflow.png\",\n",
    "    alt=\"GX Cloud and GX Core interactions in Cookbook3\",\n",
    "    width=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Verify GX Cloud connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Before working through the tutorial, check that your GX Cloud organization credentials are available in this notebook environment, and log in to GX Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Check that GX Cloud credentials are defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Valid GX Cloud organization credentials need to be provided for GX Core to persist workflow configuration and validation results to GX Cloud. Run the code below to check that your credentials are availabe in this notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tutorial.cloud.gx_cloud_credentials_exist():\n",
    "    print(\n",
    "        \"Found stored credentials in the GX_CLOUD_ORGANIZATION_ID and GX_CLOUD_ACCESS_TOKEN environment variables.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "```{warning} GX Cloud credential error\n",
    "If `tutorial.cloud.check_for_gx_cloud_credentials_exist()` rasies a `ValueError` indicating that `GX_CLOUD_ORGANIZATION_ID` or `GX_CLOUD_ACCESS_TOKEN` is undefined, ensure that you have provided your GX Cloud organization id and access token when starting Docker compose.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Log into GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "In a separate browser window or tab, log in to [GX Cloud](https://hubs.ly/Q02TyCZS0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Connect to source data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "In this tutorial, you will validate customer profile information that is hosted in a publicly available Postgres database, provided by GX. The customer profile data extends the sample customer data used in [Cookbook 1](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb). Data for each customer includes their age (in years) and annual income (in USD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\n",
    "    \"select count(*) from customer_profile\",\n",
    "    con=tutorial.db.get_cloud_postgres_engine(),\n",
    ").iloc[0][\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\n",
    "    \"select * from customer_profile limit 5\",\n",
    "    con=tutorial.db.get_cloud_postgres_engine(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Profile source data and determine data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The scenario explored in this cookbook assumes that the data has been vetted for schema adherence and completeness. Notably, all rows contain required fields and data is non-null and in a valid format.\n",
    "\n",
    "The Expectations that you create will assess the distribution of the customer profile dataset - representative of data testing performed before using data for analysis or machine learning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial.cookbook3.visualize_customer_age_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial.cookbook3.visualize_customer_income_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "You will use the following Expectations in this cookbook to validate distribution of the sample customer profile data:\n",
    "* The minimum customer age is between 20 and 25 years\n",
    "* The maximum customer age is 85 years or younger\n",
    "* The median customer annual income between 45k and 50k, with a standard deviation of 10k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## GX validation workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "The GX data validation workflow was introduced in [Cookbook 1](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb) and [Cookbook 2](Cookbook_2_Validate_data_during_ingestion_take_action_on_failures.ipynb); refer to these cookbooks for provided walkthroughs of the following GX components:\n",
    "* Data definition: Data Source, Data Asset, Batch Definition, Batch\n",
    "* Data quality definition: Expectation, Expectation Suite\n",
    "* Data Validation: Validation Definition, Checkpoint, Validation Result\n",
    "\n",
    "This cookbook will provide additional detail on the Data Context and discuss the choice of Data Context when introducing GX Cloud into your data validation workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Ephemeral and Cloud Data Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "All GX Core workflows start with the creation of a Data Contex. A Data Context is the Python object that serves as an entrypoint for the GX Core Python library, and it also manages the settings and metadata for your GX workflow.\n",
    "\n",
    "* An **Ephemeral Data Context** stores the configuration of your GX workflow in memory. Workflow configurations do not persist beyond the current notebook or Python session.\n",
    "\n",
    "  ```\n",
    "  context = gx.get_context(mode=\"ephemeral\")\n",
    "  ```\n",
    "\n",
    "* A **Cloud Data Context** stores the configuration of your GX workflow in GX Cloud. Configurations stored in GX Cloud are accessible by others in your organization and can be used across sessions and mediums - in Python notebooks, Python scripts, and orchestrators that support Python. When creating a Cloud Data Context, you need to provide credentials for the specific GX Cloud organization that you want to use.\n",
    "\n",
    "  ```\n",
    "  context = gx.get_context(\n",
    "      mode=\"cloud\",\n",
    "      cloud_organization_id=\"<my-gx-cloud-org-id>\",\n",
    "      cloud_access_token=\"<my-gx-cloud-access-token>\"\n",
    "  )\n",
    "  ```\n",
    "\n",
    "For additional detail on Data Contexts, see [Create a Data Context](https://docs.greatexpectations.io/docs/core/set_up_a_gx_environment/create_a_data_context) in the GX Core documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "The `gx.get_context()` method, when called with no arguments, will auto-discover your GX Cloud organization id and access token credentials if they are available as the `GX_CLOUD_ORGANIZATION_ID` and `GX_CLOUD_ACCESS_TOKEN` environment variables, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = gx.get_context()\n",
    "\n",
    "if (os.getenv(\"GX_CLOUD_ORGANIZATION_ID\", None) is not None) and (\n",
    "    os.getenv(\"GX_CLOUD_ACCESS_TOKEN\", None) is not None\n",
    "):\n",
    "    assert isinstance(context, gx.data_context.CloudDataContext)\n",
    "    print(\"GX Cloud credentials found, created CloudDataContext.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Define validation workflow and persist configuration in GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "```{admonition} Reminder: Adding GX components to the Data Context\n",
    "GX components are unique on name. Once a component is created with the Data Context, adding another component with the same name will cause an error. To enable repeated execution of cookbook cells that add GX workflow components, you will see the following pattern:\n",
    "\n",
    "    try:\n",
    "        Add a new component(s) to the context\n",
    "    except:\n",
    "        Get component(s) from the context by name, or delete and recreate the component(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Create the GX Data Asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Create the Cloud Data Context and the initial components that define a Data Asset for the sample customer profile data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Cloud Data Context.\n",
    "context = gx.get_context()\n",
    "\n",
    "# Create the Data Source, Data Asset, and Batch Definition.\n",
    "try:\n",
    "    data_source = context.data_sources.add_postgres(\n",
    "        \"GX tutorial\", connection_string=tutorial.db.get_gx_postgres_connection_string()\n",
    "    )\n",
    "    data_asset = data_source.add_table_asset(\n",
    "        name=\"customer profiles\", table_name=\"customer_profile\"\n",
    "    )\n",
    "    batch_definition = data_asset.add_batch_definition_whole_table(\n",
    "        \"customer profiles batch definition\"\n",
    "    )\n",
    "\n",
    "except:\n",
    "    data_source = context.data_sources.get(\"GX tutorial\")\n",
    "    data_asset = data_source.get_asset(name=\"customer profiles\")\n",
    "    batch_definition = data_asset.get_batch_definition(\n",
    "        \"customer profiles batch definition\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "#### Examine the Data Asset in GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Since the Cloud Data Context was used to create the Data Source and Data Asset, you will now see these components in your GX Cloud organization. View the Data Asset in the [GX Cloud UI](https://hubs.ly/Q02TyCZS0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_new_data_asset.png\",\n",
    "    alt=\"Data Asset created in GX Cloud using a Cloud Data Context\",\n",
    "    width=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "You will see that the newly created Data Asset does not contain any Expectations or Validation Results yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_new_asset_no_expectations_validations.png\",\n",
    "    alt=\"A Data Asset newly created with GX Core does not yet have Expectations or Validation Results in GX Cloud\",\n",
    "    width=700,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Add Expectations and a Checkpoint to the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Continue to build your GX validation workflow, adding the Expectation Suite, Expectations, Validation Definition, and Checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTATION_SUITE_NAME = \"Customer profile expectations\"\n",
    "VALIDATION_DEFINTION_NAME = \"Customer profile validation definition\"\n",
    "CHECKPOINT_NAME = \"Customer profile checkpoint\"\n",
    "\n",
    "\n",
    "def create_gx_validation_workflow_components(\n",
    "    expectation_suite_name: str, validation_definition_name: str, checkpoint_name: str\n",
    ") -> gx.Checkpoint:\n",
    "    \"\"\"Create the Expectation Suite, Validation Definition, and Checkpoint for the Cookbook 3 workflow.\n",
    "\n",
    "    Returns:\n",
    "        GX Checkpoint object\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the Expectation Suite.\n",
    "    expectation_suite = context.suites.add(\n",
    "        gx.ExpectationSuite(name=EXPECTATION_SUITE_NAME)\n",
    "    )\n",
    "\n",
    "    # Add Expectations to Expectation Suite.\n",
    "    expectations = [\n",
    "        gxe.ExpectColumnMinToBeBetween(column=\"age\", min_value=20, max_value=25),\n",
    "        gxe.ExpectColumnMaxToBeBetween(column=\"age\", max_value=90),\n",
    "        gxe.ExpectColumnMedianToBeBetween(\n",
    "            column=\"annual_income_usd\", min_value=45_000, max_value=50_000\n",
    "        ),\n",
    "        gxe.ExpectColumnStdevToBeBetween(\n",
    "            column=\"annual_income_usd\", min_value=10_000, max_value=10_000\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    for expectation in expectations:\n",
    "        expectation_suite.add_expectation(expectation)\n",
    "\n",
    "    expectation_suite.save()\n",
    "\n",
    "    # Create the Validation Definition.\n",
    "    validation_definition = context.validation_definitions.add(\n",
    "        gx.ValidationDefinition(\n",
    "            name=VALIDATION_DEFINTION_NAME,\n",
    "            data=batch_definition,\n",
    "            suite=expectation_suite,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the Checkpoint.\n",
    "    checkpoint = context.checkpoints.add(\n",
    "        gx.Checkpoint(\n",
    "            name=CHECKPOINT_NAME,\n",
    "            validation_definitions=[validation_definition],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "# Create (or recreate: delete & create) the cookbook workflow components.\n",
    "try:\n",
    "    checkpoint = create_gx_validation_workflow_components(\n",
    "        expectation_suite_name=EXPECTATION_SUITE_NAME,\n",
    "        validation_definition_name=VALIDATION_DEFINTION_NAME,\n",
    "        checkpoint_name=CHECKPOINT_NAME,\n",
    "    )\n",
    "\n",
    "except:\n",
    "    context.checkpoints.delete(name=CHECKPOINT_NAME)\n",
    "    context.validation_definitions.delete(name=VALIDATION_DEFINTION_NAME)\n",
    "    expectation_suite = context.suites.delete(name=EXPECTATION_SUITE_NAME)\n",
    "\n",
    "    checkpoint = create_gx_validation_workflow_components(\n",
    "        expectation_suite_name=EXPECTATION_SUITE_NAME,\n",
    "        validation_definition_name=VALIDATION_DEFINTION_NAME,\n",
    "        checkpoint_name=CHECKPOINT_NAME,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### Examine Expectations in GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Examine the newly added Expectations in the [GX Cloud UI](https://hubs.ly/Q02TyCZS0). You will see the GX Core-created Expectations under the **Cloud API** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_expectations_added.png\",\n",
    "    alt=\"GX Cloud display of Expectations added using GX Core\",\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Validate the sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "The GX workflow configuration is now persisted in your GX Cloud organization, accessible via the Cloud Data Context. Run the Checkpoint to validate the sample customer profile data, and then explore the Validation Results in GX Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "#### Run the Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "Run the Checkpoint to validate the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_result = checkpoint.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### View results in GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "The Validation Result object can be extracted from the returned Checkpoint Result object. When produced using a Cloud Data Context, the Validation Result object provides a `result_url` field that contains a direct link to your Validation Results in GX Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result = checkpoint_result.run_results[\n",
    "    list(checkpoint_result.run_results.keys())[0]\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Click this link to view your Validation Results in GX Cloud:\\n\\n{validation_result.result_url}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_linked_validation_results.png\",\n",
    "    alt=\"Validation Results of Expectations against sample customer profile data\",\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "The Validation Results for the `Customer profile expectations` suite inform you that three out of four Expectations passed. The Expectation that the standard deviation of customer annual income is 10k failed - the results indicate that the observed standard deviation is slightly lower, about $9.6k.\n",
    "\n",
    "For the purposes of this tutorial, it is important that an Expectation failed, rather than why it failed, so that you can experience the exploration of both passing and failing results in GX Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## Integrate GX Cloud validation in the Airflow DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "You have run data validation from this notebook, next, you will run data validation within an Airflow DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### Inspect DAG code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Examine the DAG code below that defines the `cookbook3_validate_postgres_table_data` pipeline. The key actions of the code are:\n",
    "* Fetch and run the GX Cloud Checkpoint.\n",
    "\n",
    "   ```\n",
    "   context = gx.get_context()\n",
    " \n",
    "   checkpoint = context.checkpoints.get(\"Customer profile checkpoint\")\n",
    "   \n",
    "   checkpoint_result = checkpoint.run()\n",
    "   ```\n",
    "\n",
    "   * Note that the code assumes that the GX Cloud credentials have been made available in the Airflow environment so that `gx.get_context()` returns a Cloud Data Context.\n",
    "   * This code snippet, customized for your desired Checkpoint, can be retrieved from GX Cloud using the validation code snippet feature. See the next section of this cookbook for more detail.\n",
    "\n",
    "* Extract and log the result of validation and GX Cloud results url.\n",
    "\n",
    "   ```\n",
    "    validation_result = checkpoint_result.run_results[\n",
    "        list(checkpoint_result.run_results.keys())[0]\n",
    "    ]\n",
    "\n",
    "    if validation_result[\"success\"]:\n",
    "        log.info(f\"Validation succeeded: {validation_result.result_url}\")\n",
    "    else:\n",
    "        log.warning(f\"Validation failed: {validation_result.result_url}\")\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat inspect.getsource(dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "### GX Cloud validation code snippet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "GX Cloud will generate a validation code snippet, which provides the code needed to run a GX Cloud Checkpoint using GX Core. The validation code snippet can be copy-pasted within an Airflow DAG to trigger a Checkpoint run. \n",
    "\n",
    "1. Navigate to the Validations tab of your Data Asset.\n",
    "2. Click the **Use code snippet** button `</>` directly to the right of the **Validate** button.\n",
    "3. Click **Generate Snippet**.\n",
    "\n",
    "This displays the Validation Expectations dialog box, which contains a GX Core 1.0.x code snippet that has been populated with the name of your Checkpoint. For instance, for the Checkpoint created by this cookbook, you'll see the following snippet:\n",
    "```\n",
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "\n",
    "checkpoint = context.checkpoints.get(\"Customer profile checkpoint\")\n",
    "\n",
    "checkpoint.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_validation_code_snippet.png\",\n",
    "    alt=\"Generate the validation code snippet in GX Cloud\",\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### View the Airflow pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "To view the `cookbook3_validate_postgres_table_data` pipeline in the Airflow UI, log into the locally running Airflow instance.\n",
    "\n",
    "1. Open [http://localhost:8080/](http://localhost:8080/) in a browser window.\n",
    "2. Log in with these credentials:\n",
    "  * Username: `admin`\n",
    "  * Password: `gx`\n",
    "\n",
    "You will see the pipeline under **DAGs** on login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Video(\"img/screencaptures/log_in_to_airflow.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### Trigger the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "You can trigger the DAG from this notebook, using the provided convenience function in the cell below, or you can trigger the DAG manually in the Airflow UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial.airflow.trigger_airflow_dag_and_wait_for_run(\n",
    "    \"cookbook3_validate_postgres_table_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "To trigger the `cookbook3_validate_postgres_table_data` DAG from the Airflow UI, click the **Trigger DAG** button (with a play icon) under *Actions*. This will queue the DAG and it will execute shortly. The successful run is indicated by the run count inside the green circle under **Runs**. The triggering of a similar DAG is shown in the clip below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Video(\"img/screencaptures/trigger_airflow_dag.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "The `cookbook3_validate_postgres_table_data` DAG can be rerun multiple times; you can experiment with running it from this notebook or from the Airflow UI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### View pipeline results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "Once the pipeline has been run, Validation Results are available in GX Cloud. You can either go directly to the GX Cloud UI, or access the link from the pipeline logs. To access the pipeline run logs in the Airflow UI:\n",
    "\n",
    "1. On the DAGs screen, click on the run(s) of interest under Runs.\n",
    "2. Click the name of the individual run you want to examine. This will load the DAG execution details.\n",
    "3. Click the Graph tab, and then the `cookbook3_validate_postgres_table_data` task box on the visual rendering.\n",
    "4. Click the Logs tab to load the DAG logs. The link to the GX Cloud results will be in the log output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Video(\n",
    "    \"img/screencaptures/cookbook3_view_pipeline_results.mp4\", width=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## Review and take action on validation results in GX Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### Review validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "When you integrate data validation into your pipeline using GX, GX Cloud provides a central UI to review and share validation results; result output is not limited to pipeline log messages.\n",
    "\n",
    "Data validation results are shown in GX Cloud on the **Validations** tab of a Data Asset. You can access these results using a direct link (as shown in this cookbook), or by navigating within the GX Cloud UI.\n",
    "\n",
    "In addition to the results of individual runs, the Validations tab provides a historical view of your data validation results over multiple runs. This consolidated view contributes to an improved understanding and monitoring of your Data Asset health and quality over time, rather than relying on point-in-time assessments of data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_gx_cloud_validations_tab_over_time.png\",\n",
    "    alt=\"GX Cloud Validations tab actions: Alert, Share, Validate\",\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### Take action on validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "GX Cloud enables you to take action on results generated by validation in your data pipeline. The key capabilities are Alerting, Sharing, and in-app triggering of Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_gx_cloud_validations_tab_actions.png\",\n",
    "    alt=\"GX Cloud Validations tab actions: Alert, Share, Validate\",\n",
    "    width=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "Alerting is enabled by default on newly created Data Assets. If any Validations fail, then you will receive an email that notifies you of the failure and provides a direct link to the failing validation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Image(\n",
    "    \"img/screencaptures/cookbook3_validation_failure_email_alert.png\",\n",
    "    alt=\"GX Cloud email alert for data validation failure\",\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "Results can easily be shared with others in your organization. Once individuals have been [added to your GX Cloud organization](https://docs.greatexpectations.io/docs/cloud/users/manage_users#invite-a-user), then you can provide a Share link that takes them directly to the validation run of interest.\n",
    "\n",
    "Validation can be triggered manually from the GX Cloud UI, enabling data developers and other stakeholders to revalidate data without needing to modify the existing data pipeline operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "This cookbook has walked you through the process of defining a validation workflow with GX Core, persisting the worfklow configuration in GX Cloud, integrating data validation in an Airflow pipeline, and then accessing and taking action on validation results in GX Cloud.\n",
    "\n",
    "[Cookbook 1](Cookbook_1_Validate_data_during_ingestion_happy_path.ipynb), [Cookbook 2](Cookbook_2_Validate_data_during_ingestion_take_action_on_failures.ipynb), and Cookbook 3 (this cookbook) have demonstrated how you can integrate data validation in a Python-enabled orchestrator using GX. While the cookbook examples have used Airflow DAGs, the same principles will apply when using GX in other orchestrators, such as Dagster, Prefect, or any other orchestrator that supports Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
